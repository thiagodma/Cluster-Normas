{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from classic_clustering import ClassicClustering\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fazendo os pré-processamentos necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#abrindo o csv com os arquivos\n",
    "df = pd.read_csv('Data.csv',sep='|',encoding='utf8')\n",
    "textos = list(df['textos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inicializo um objeto da classe que me ajuda com o pré-processamento\n",
    "cc = ClassicClustering()\n",
    "#defino as stopwords padrão da classe\n",
    "cc.define_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.35 s, sys: 135 ms, total: 7.48 s\n",
      "Wall time: 7.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#recodifico tudo em utf-8, retiro caracteres especiais e converto tudo para letra minúscula\n",
    "textos1 = [cc.limpa_utf8(texto.lower()) for texto in textos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "portaria/ms no 08, de 10 de abril de 1987 (publicada em dou, de 28 de abril de 1987) o diretor da divisao nacional de vigilancia sanitaria de produtos saneantes domissanitarios, no uso de suas atribuicoes e considerando o risco oferecido pelas formulacoes alaclinas, quando apresentadas sob a forma de liquido premido ou para pulverizacao, que podem provocar serias lesoes em mucosas oculares ou do trato respiratorio, resolve: 1o proibir a fabricacao e comercializacao de saneantes domissanitarios fortemente alcalinos apresentados sob a forma de liquido premido (aerossol), ou liquido para pulverizacao, tais como produtos para limpeza de fornos e desincrustacao de gorduras, de uso domestico. § unico: executam-se do acima disposto os produtos para uso profissional, os quais, nesse caso, devem ser aplicadas por pessoa habilitada, devidamente protegido por roupas, mascaras, oculos e indumetaria apropriados. 2o para efeito da presente sao considerados produtos fortemente alcalinos aqueles conte\n"
     ]
    }
   ],
   "source": [
    "print(textos1[0][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21 s, sys: 184 ms, total: 21.2 s\n",
      "Wall time: 21.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#retiro romanos e stopwords\n",
    "textos2 = []\n",
    "for texto in textos1:\n",
    "    novo_texto = [cc.tira_stopwords_e_romanos(palavra) for palavra in texto.split()]\n",
    "    textos2.append(' '.join(novo_texto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "portaria/ms  08,  10  abril  1987 (publicada  dou,  28  abril  1987)  diretor  divisao nacional  vigilancia sanitaria  produtos saneantes domissanitarios,  uso   atribuicoes  considerando  risco oferecido  formulacoes alaclinas,  apresentadas   forma  liquido premido   pulverizacao,  podem provocar serias lesoes  mucosas oculares   trato respiratorio, resolve: 1o proibir  fabricacao  comercializacao  saneantes domissanitarios fortemente alcalinos apresentados   forma  liquido premido (aerossol),  liquido  pulverizacao, tais  produtos  limpeza  fornos  desincrustacao  gorduras,  uso domestico.  unico: executam-se  acima disposto  produtos  uso profissional,  quais, nesse caso, devem  aplicadas  pessoa habilitada, devidamente protegido  roupas, mascaras, oculos  indumetaria apropriados. 2o  efeito  presente  considerados produtos fortemente alcalinos  contendo bases inorganicas livres  teores acima  1%, inclusive. 3o  produtos alcalinos, assim compreendidos  cuja medida  ph exceda, 8,5, \n"
     ]
    }
   ],
   "source": [
    "print(textos2[0][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comecou a fazer o stemming.\n",
      "Tempo para fazer o stemming: 118.23791909217834\n",
      "\n",
      "CPU times: user 1min 59s, sys: 229 ms, total: 2min\n",
      "Wall time: 2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cc.textos_tratados = textos2\n",
    "cc.stem()\n",
    "base_tfidf = cc.vec_tfidf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "portaria/m 08, 10 abril 1987 (public dou, 28 abril 1987) dire divisa nacion vigilanc sanit produt sane domissanitarios, uso atribuico consider risc oferec formulaco alaclinas, apresent form liqu prem pulverizacao, pod provoc ser leso mucos ocul trat respiratorio, resolve: 1o proib fabricaca comercializaca sane domissanitari fort alcalin apresent form liqu prem (aerossol), liqu pulverizacao, tal produt limp forn desincrustaca gorduras, uso domestico. unico: executam-s acim dispost produt uso profissional, quais, ness caso, dev aplic pesso habilitada, devid proteg roupas, mascaras, ocul indumet apropriados. 2o efeit pres consider produt fort alcalin cont bas inorgan livr te acim 1%, inclusive. 3o produt alcalinos, assim compreend cuj med ph exceda, 8,5, fic abrang dispost artig 1o. 4o fic conced praz 90 (noventa) dias, fabric produt registr event dat anteri publicaca pres infrij disposi aqui, contidos, promov recolh unidad exist comercio, find qual mesm recolh fiscalizaca inutilizadas. a\n"
     ]
    }
   ],
   "source": [
    "print(cc.textos_stem[0][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Começou a redução de dimensionalidade.\n",
      "Número de dimensões de entrada: 51330\n",
      "600 dimensões explicam 0.8112234061058099 da variância.\n",
      "Tempo para fazer a redução de dimensionalidade: 30.418655157089233\n",
      "\n",
      "CPU times: user 1min, sys: 14.2 s, total: 1min 14s\n",
      "Wall time: 30.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_dims = 600\n",
    "X = cc.SVD(base_tfidf, n_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agora vamos rodar os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gerando labels para as normas (sei que não é a forma mais esperta de se fazer isso)\n",
    "macrotema_por_norma = list(df['macrotemas'])\n",
    "macrotemas = list(dict.fromkeys(macrotema_por_norma))\n",
    "\n",
    "di = dict.fromkeys(macrotema_por_norma)\n",
    "i=0\n",
    "for macrotema in macrotemas:\n",
    "    di[macrotema] = i\n",
    "    i+=1\n",
    "\n",
    "y = np.zeros(len(macrotema_por_norma))\n",
    "i=0\n",
    "for m in macrotema_por_norma:\n",
    "    y[i] = di[m]\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizando as features com média zero e std 1\n",
    "#X = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separando em dados de treinamento e validação\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    LogisticRegression(random_state=42, solver='lbfgs', multi_class='multinomial'),\n",
    "    SVC(C=1,gamma='scale'),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    AdaBoostClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8111111111111111\n",
      "0.8333333333333334\n",
      "0.2361111111111111\n",
      "0.4111111111111111\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    model.fit(X_train,y_train)\n",
    "    print(model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 80 candidates, totalling 800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 3 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   46.5s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 14.2min\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed: 14.3min finished\n",
      "/usr/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/usr/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia na base de treino da LR com hiperparâmetros ajustados:  0.9680555555555556\n",
      "Acuracia na base de teste da LR com hiperparâmetros ajustados:  0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([('classifier' , SVC(random_state=0,decision_function_shape='ovo'))])\n",
    "\n",
    "param_grid = [\n",
    "    {'classifier' : [SVC()],\n",
    "    'classifier__C' : np.logspace(-4, 4, 20), # valores de 0 a 10.000\n",
    "    'classifier__kernel' : ['linear','rbf','poly','sigmoid']}]\n",
    "\n",
    "# Create grid search object\n",
    "clf = GridSearchCV(pipe, param_grid = param_grid, cv = 10, verbose=True, n_jobs=-1)\n",
    "best_clf = clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Acuracia na base de treino da LR com hiperparâmetros ajustados: \", clf.score(X_train, y_train))\n",
    "print(\"Acuracia na base de teste da LR com hiperparâmetros ajustados: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/numpy/core/fromnumeric.py:61: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#acessando os resultados do grid search\n",
    "df = pd.DataFrame(clf.cv_results_)\n",
    "#achando quais foram os parâmetros do melhor classificador\n",
    "np.argmax(df['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean_fit_time                                                         3.50312\n",
       "std_fit_time                                                         0.317659\n",
       "mean_score_time                                                      0.252879\n",
       "std_score_time                                                      0.0585404\n",
       "param_classifier            SVC(C=1438.44988828766, cache_size=200, class_...\n",
       "param_classifier__C                                                   1438.45\n",
       "param_classifier__kernel                                              sigmoid\n",
       "params                      {'classifier': SVC(C=1438.44988828766, cache_s...\n",
       "split0_test_score                                                    0.807947\n",
       "split1_test_score                                                    0.854305\n",
       "split2_test_score                                                    0.812081\n",
       "split3_test_score                                                    0.898649\n",
       "split4_test_score                                                    0.815068\n",
       "split5_test_score                                                    0.840278\n",
       "split6_test_score                                                    0.879433\n",
       "split7_test_score                                                    0.841727\n",
       "split8_test_score                                                    0.860294\n",
       "split9_test_score                                                    0.874074\n",
       "mean_test_score                                                      0.847917\n",
       "std_test_score                                                       0.029394\n",
       "rank_test_score                                                             1\n",
       "Name: 71, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printando os parâmetros do melhor classificador\n",
    "df.iloc[71,:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
